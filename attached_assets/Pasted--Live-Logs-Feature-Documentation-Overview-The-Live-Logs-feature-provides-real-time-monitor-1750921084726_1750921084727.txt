# Live Logs Feature Documentation

## Overview

The Live Logs feature provides real-time monitoring of your Local LLM application through a web-based interface. It includes live streaming of log events, filtering capabilities, and historical log viewing.

## Features

- **Real-time Log Streaming**: Uses Server-Sent Events (SSE) to stream logs live
- **Interactive Web Interface**: Modern, dark-themed interface with filtering and search
- **Multiple Log Types**: API calls, responses, errors, and system events
- **Filtering Options**: Filter by log level, type, and search terms
- **Historical Data**: View recent logs on page load
- **Statistics**: Real-time counters for total logs and errors
- **Auto-scroll**: Automatically scroll to newest logs

## API Endpoints

### 1. `/api/v1/logs` (GET)
**Description**: Serves the live logs viewer web interface

**Usage**:
```bash
curl http://localhost:5000/api/v1/logs
```

**Response**: HTML page with the live logs interface

---

### 2. `/api/v1/logs/stream` (GET)
**Description**: Server-Sent Events stream for real-time logs

**Usage**:
```bash
curl -N -H "Accept: text/event-stream" http://localhost:5000/api/v1/logs/stream
```

**Response Format**: SSE stream with JSON data
```
data: {"timestamp": "2025-06-26T10:30:45.123456", "level": "INFO", "message": "Incoming request", "type": "request", "method": "GET", "url": "http://localhost:5000/api/v1/models"}

data: {"timestamp": "2025-06-26T10:30:45.234567", "level": "INFO", "message": "Outgoing response", "type": "response", "status_code": 200, "duration_ms": 45.67}
```

---

### 3. `/api/v1/logs/recent` (GET)
**Description**: Get recent logs for initial page load

**Parameters**:
- `lines` (int, optional): Number of log lines to return (default: 100)
- `type` (string, optional): Type of logs ('all', 'api', 'errors') (default: 'all')

**Usage**:
```bash
# Get last 50 logs
curl "http://localhost:5000/api/v1/logs/recent?lines=50"

# Get only error logs
curl "http://localhost:5000/api/v1/logs/recent?type=errors&lines=25"
```

**Sample Response**:
```json
[
  {
    "timestamp": "2025-06-26T10:30:45.123456",
    "level": "INFO",
    "message": "Incoming request",
    "module": "logger",
    "type": "request",
    "request_id": "req_1719396645123456",
    "method": "GET",
    "url": "http://localhost:5000/api/v1/models",
    "endpoint": "list_models",
    "remote_addr": "127.0.0.1",
    "user_agent": "curl/7.68.0",
    "content_type": null,
    "content_length": null,
    "args": {}
  },
  {
    "timestamp": "2025-06-26T10:30:45.234567",
    "level": "INFO",
    "message": "Outgoing response",
    "module": "logger",
    "type": "response",
    "request_id": "req_1719396645123456",
    "method": "GET",
    "url": "http://localhost:5000/api/v1/models",
    "endpoint": "list_models",
    "status_code": 200,
    "content_type": "application/json",
    "content_length": 1234,
    "duration_ms": 45.67
  },
  {
    "timestamp": "2025-06-26T10:31:15.987654",
    "level": "ERROR",
    "message": "Error response - 404",
    "module": "logger",
    "type": "response",
    "request_id": "req_1719396675987654",
    "method": "GET",
    "url": "http://localhost:5000/api/v1/models/nonexistent.gguf",
    "endpoint": "delete_model",
    "status_code": 404,
    "content_type": "application/json",
    "content_length": 45,
    "duration_ms": 12.34
  }
]
```

---

### 4. `/api/v1/logs/stats` (GET)
**Description**: Get log statistics and analytics

**Parameters**:
- `hours` (int, optional): Time period in hours for analysis (default: 24)

**Usage**:
```bash
# Get stats for last 24 hours
curl "http://localhost:5000/api/v1/logs/stats"

# Get stats for last 6 hours
curl "http://localhost:5000/api/v1/logs/stats?hours=6"
```

**Sample Response**:
```json
{
  "api_stats": {
    "total_requests": 150,
    "endpoints": {
      "generate_response": 45,
      "list_models": 30,
      "upload_model": 5,
      "health_check": 70
    },
    "methods": {
      "GET": 100,
      "POST": 50
    },
    "status_codes": {
      "200": 140,
      "404": 8,
      "500": 2
    },
    "avg_response_time": 234.56,
    "response_times": [45.67, 123.45, 234.56, ...]
  },
  "error_summary": {
    "total_errors": 10,
    "error_types": {
      "FileNotFoundError": 8,
      "ValidationError": 2
    },
    "endpoints_with_errors": {
      "delete_model": 6,
      "generate_response": 4
    },
    "status_codes": {
      "404": 8,
      "500": 2
    }
  },
  "timeframe_hours": 24
}
```

## Implementation Guide

### Step 1: Access the Live Logs Interface

1. Start your Local LLM application:
```bash
python main.py
```

2. Open your web browser and navigate to:
```
http://localhost:5000/api/v1/logs
```

### Step 2: Using the Interface

1. **Connect to Live Stream**: Click the "Connect" button to start receiving live logs
2. **Filter Logs**: Use the dropdown filters to show only specific log levels or types
3. **Search**: Use the search box to find specific log messages
4. **Auto-scroll**: Toggle auto-scroll to automatically scroll to new logs
5. **Clear**: Clear the current log display (doesn't affect actual log files)

### Step 3: Programmatic Access

#### JavaScript Example (Client-side SSE):
```javascript
const eventSource = new EventSource('/api/v1/logs/stream');

eventSource.onmessage = function(event) {
    const log = JSON.parse(event.data);
    console.log('New log:', log);
    
    // Process the log entry
    if (log.level === 'ERROR') {
        console.error('Error detected:', log.message);
    }
};

eventSource.onerror = function(event) {
    console.error('SSE connection error');
};
```

#### Python Example (Server-side):
```python
import requests
import json

# Get recent logs
response = requests.get('http://localhost:5000/api/v1/logs/recent?lines=10')
recent_logs = response.json()

for log in recent_logs:
    print(f"[{log['timestamp']}] {log['level']}: {log['message']}")

# Get statistics
stats_response = requests.get('http://localhost:5000/api/v1/logs/stats')
stats = stats_response.json()

print(f"Total requests in last 24h: {stats['api_stats']['total_requests']}")
print(f"Total errors in last 24h: {stats['error_summary']['total_errors']}")
```

#### cURL Examples:
```bash
# Stream logs (will keep connection open)
curl -N -H "Accept: text/event-stream" http://localhost:5000/api/v1/logs/stream

# Get last 20 logs
curl "http://localhost:5000/api/v1/logs/recent?lines=20" | jq '.'

# Get error stats for last 6 hours
curl "http://localhost:5000/api/v1/logs/stats?hours=6" | jq '.error_summary'

# Monitor for errors in real-time
curl -N -H "Accept: text/event-stream" http://localhost:5000/api/v1/logs/stream | \
  grep '"level":"ERROR"'
```

## Log Entry Structure

### Request Log Entry:
```json
{
  "timestamp": "2025-06-26T10:30:45.123456",
  "level": "INFO",
  "message": "Incoming request",
  "module": "logger",
  "type": "request",
  "request_id": "req_1719396645123456",
  "method": "POST",
  "url": "http://localhost:5000/api/v1/generate",
  "endpoint": "generate_response",
  "remote_addr": "127.0.0.1",
  "user_agent": "curl/7.68.0",
  "content_type": "application/json",
  "content_length": 150,
  "args": {},
  "request_body": {
    "question": "Hello, how are you?",
    "model_name": "llama-3.2-3b"
  }
}
```

### Response Log Entry:
```json
{
  "timestamp": "2025-06-26T10:30:47.234567",
  "level": "INFO",
  "message": "Outgoing response",
  "module": "logger",
  "type": "response",
  "request_id": "req_1719396645123456",
  "method": "POST",
  "url": "http://localhost:5000/api/v1/generate",
  "endpoint": "generate_response",
  "status_code": 200,
  "content_type": "application/json",
  "content_length": 450,
  "duration_ms": 2111.34,
  "response_body": {
    "success": true,
    "response": "Hello! I'm doing well, thank you for asking...",
    "model_name": "llama-3.2-3b",
    "generation_time": 2.05
  }
}
```

### Error Log Entry:
```json
{
  "timestamp": "2025-06-26T10:31:15.987654",
  "level": "ERROR",
  "message": "Model not found",
  "module": "logger",
  "type": "response",
  "request_id": "req_1719396675987654",
  "method": "GET",
  "url": "http://localhost:5000/api/v1/models/nonexistent.gguf",
  "endpoint": "delete_model",
  "status_code": 404,
  "content_type": "application/json",
  "content_length": 45,
  "duration_ms": 12.34,
  "response_body": {
    "error": "Model not found"
  }
}
```

### Custom Event Log Entry:
```json
{
  "timestamp": "2025-06-26T10:32:00.111222",
  "level": "INFO",
  "message": "Model uploaded successfully: new-model.gguf",
  "module": "logger",
  "type": "custom_event",
  "event_type": "model_upload",
  "filename": "new-model.gguf",
  "file_size": 4294967296,
  "model_info": {
    "name": "new-model.gguf",
    "size": "4.0 GB",
    "created": "2025-06-26T10:32:00"
  }
}
```

## Configuration

The live logs feature is controlled by several configuration options in `config.py`:

```python
# Logging settings
LOG_DIR = './logs'                    # Directory for log files
LOG_MAX_BYTES = 10 * 1024 * 1024     # Max size per log file (10MB)
LOG_BACKUP_COUNT = 5                  # Number of backup files to keep
LOG_API_CALLS = True                  # Enable API call logging
```

## Troubleshooting

### Common Issues:

1. **"Logger not available" error**:
   - Ensure `LOG_API_CALLS = True` in your config
   - Restart the application after configuration changes

2. **SSE connection fails**:
   - Check firewall settings
   - Verify the application is running on the expected port
   - Some corporate networks block SSE connections

3. **No recent logs showing**:
   - Check if the logs directory exists and is writable
   - Verify log files are being created in the configured `LOG_DIR`

4. **High memory usage**:
   - The stream handler keeps a queue of recent logs in memory
   - Consider reducing the queue size for high-volume applications

## Performance Considerations

- The live streaming feature uses Server-Sent Events, which maintains an open HTTP connection
- Log files are rotated automatically when they reach the configured size limit
- The in-memory log queue has a maximum size to prevent memory leaks
- Heavy log filtering on the client side may impact browser performance with many logs

## Security Notes

- The logs interface is accessible without authentication by default
- Consider adding authentication for production environments
- Log data may contain sensitive information - review what gets logged
- The SSE endpoint allows CORS from any origin - restrict this in production

## Integration Examples

### Monitoring Script:
```bash
#!/bin/bash
# Monitor for errors and send alerts

curl -N -H "Accept: text/event-stream" http://localhost:5000/api/v1/logs/stream | \
while IFS= read -r line; do
  if echo "$line" | grep -q '"level":"ERROR"'; then
    echo "$(date): ERROR detected: $line"
    # Add your alerting logic here (email, Slack, etc.)
  fi
done
```

### Log Analysis:
```python
import requests
import json
from collections import Counter

# Analyze API usage patterns
response = requests.get('http://localhost:5000/api/v1/logs/recent?lines=1000&type=api')
logs = response.json()

# Count requests by endpoint
endpoints = [log.get('endpoint') for log in logs if log.get('type') == 'request']
endpoint_counts = Counter(endpoints)

print("Most used endpoints:")
for endpoint, count in endpoint_counts.most_common(5):
    print(f"  {endpoint}: {count}")
```
